# Real-Time Stocks Market Data Pipeline

![Snowflake](https://img.shields.io/badge/Snowflake-29B5E8?logo=snowflake&logoColor=white)
![DBT](https://img.shields.io/badge/dbt-FF694B?logo=dbt&logoColor=white)
![Apache Airflow](https://img.shields.io/badge/Apache%20Airflow-017CEE?logo=apacheairflow&logoColor=white)
![Python](https://img.shields.io/badge/Python-3776AB?logo=python&logoColor=white)
![Kafka](https://img.shields.io/badge/Apache%20Kafka-231F20?logo=apachekafka&logoColor=white)
![Docker](https://img.shields.io/badge/Docker-2496ED?logo=docker&logoColor=white)
![Power BI](https://img.shields.io/badge/Power%20BI-F2C811?logo=powerbi&logoColor=black)

---

## ðŸ“Œ Project Overview
This project demonstrates an **end-to-end real-time data pipeline** using the **Modern Data Stack**.  
We capture **live stock market data** from an external API, stream it in real time, orchestrate transformations, and deliver analytics-ready insights â€” all in one unified project.

![Architecture (1)](https://github.com/user-attachments/assets/6b49eb4d-4bf7-473d-9281-50c20b241760)


---

## âš¡ Tech Stack
- **Snowflake** â†’ Cloud Data Warehouse  
- **DBT** â†’ SQL-based Transformations  
- **Apache Airflow** â†’ Workflow Orchestration  
- **Apache Kafka** â†’ Real-time Streaming  
- **Python** â†’ Data Fetching & API Integration  
- **Docker** â†’ Containerization  
- **Power BI** â†’ Data Visualization  

---

## âœ… Key Features
- Fetching **live stock market data** (not simulated) from an API  
- Real-time streaming pipeline with **Kafka**  
- Orchestrated ETL workflow using **Airflow**  
- Transformations using **DBT** inside Snowflake  
- Scalable cloud warehouse powered by **Snowflake**  
- Analytics-ready **Power BI dashboards**  

---

## ðŸ“‚ Repository Structure
real-time-stocks-pipeline/
â”œâ”€â”€ producer/                     # Kafka producer (Finnhub API)
â”‚   â””â”€â”€ stock_producer.py
â”œâ”€â”€ consumer/                     # Kafka consumer (MinIO sink)
â”‚   â””â”€â”€ stock_consumer.py
â”œâ”€â”€ dbt_stocks/models/
â”‚   â”œâ”€â”€ bronze
â”‚   â”‚   â”œâ”€â”€ bronze_stg_stock_quotes.sql
â”‚   â”‚   â””â”€â”€ sources.yml
â”‚   â”œâ”€â”€ silver
â”‚   â”‚   â””â”€â”€ silver_clean_stock_quotes.sql
â”‚   â””â”€â”€ gold
â”‚   â”‚   â”œâ”€â”€ gold_candlestick.sql
â”‚   â”‚   â”œâ”€â”€ gold_kpi.sql
â”‚   â”‚   â””â”€â”€ gold_treechart.sql
â”œâ”€â”€ dag/
â”‚   â””â”€â”€ minio_to_snowflake.py
â”œâ”€â”€ docker-compose.yml            # Kafka, Zookeeper, MinIO, Airflow, Postgres
â”œâ”€â”€ requirements.txt
â”‚â”€â”€ README.md # Documentation

---

## ðŸš€ Getting Started
1. Clone this repo and set up environment  
2. Start Kafka + Airflow services via Docker  
3. Run the Python producer to fetch live stock data  
4. Data flows into Snowflake â†’ DBT applies transformations  
5. Orchestrate everything with Airflow  
6. Connect Power BI for visualization  

---

## ðŸ“Š Final Deliverables
- **Automated real-time data pipeline**  
- **Snowflake tables (Bronze â†’ Silver â†’ Gold)**  
- **Transformed analytics models with DBT**  
- **Orchestrated DAGs in Airflow**  
- **Power BI dashboard with live insights**  

---

**Author**: *Jaya Chandra Kadiveti* 

**LinkedIn**: [username](https://www.linkedin.com/in/jayachandrakadiveti/) 

**Contact**: [Kadivetijayachandra@gmail.com](mailto:Kadivetijayachandra@gmail.com)
